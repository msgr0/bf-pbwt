@article{abouelhodaReplacingSuffixTrees2004,
  title = {Replacing Suffix Trees with Enhanced Suffix Arrays},
  author = {Abouelhoda, Mohamed Ibrahim and Kurtz, Stefan and Ohlebusch, Enno},
  year = {2004},
  month = mar,
  journal = {Journal of Discrete Algorithms},
  series = {The 9th {{International Symposium}} on {{String Processing}} and {{Information Retrieval}}},
  volume = {2},
  number = {1},
  pages = {53--86},
  issn = {1570-8667},
  doi = {10.1016/S1570-8667(03)00065-0},
  urldate = {2025-04-07},
  abstract = {The suffix tree is one of the most important data structures in string processing and comparative genomics. However, the space consumption of the suffix tree is a bottleneck in large scale applications such as genome analysis. In this article, we will overcome this obstacle. We will show how every algorithm that uses a suffix tree as data structure can systematically be replaced with an algorithm that uses an enhanced suffix array and solves the same problem in the same time complexity. The generic name enhanced suffix array stands for data structures consisting of the suffix array and additional tables. Our new algorithms are not only more space efficient than previous ones, but they are also faster and easier to implement.},
  keywords = {Genome comparison,Pattern matching,Repeat analysis,Suffix array,Suffix tree},
  file = {/Users/msgro/Zotero/storage/9M23U3HB/Abouelhoda et al. - 2004 - Replacing suffix trees with enhanced suffix arrays.pdf;/Users/msgro/Zotero/storage/5F5WZ72F/S1570866703000650.html}
}

@article{alankoFindingAllMaximal2020,
  title = {Finding All Maximal Perfect Haplotype Blocks in Linear Time},
  author = {Alanko, Jarno and Bannai, Hideo and Cazaux, Bastien and Peterlongo, Pierre and Stoye, Jens},
  year = {2020},
  month = dec,
  journal = {Algorithms for Molecular Biology},
  volume = {15},
  number = {1},
  pages = {2},
  issn = {1748-7188},
  doi = {10.1186/s13015-020-0163-6},
  urldate = {2025-03-17},
  abstract = {Recent large-scale community sequencing efforts allow at an unprecedented level of detail the identification of genomic regions that show signatures of natural selection. Traditional methods for identifying such regions from individuals' haplotype data, however, require excessive computing times and therefore are not applicable to current datasets. In 2019, Cunha et al. (Advances in bioinformatics and computational biology: 11th Brazilian symposium on bioinformatics, BSB 2018, Niter{\'o}i, Brazil, October 30 - November 1, 2018, Proceedings, 2018. https://doi. org/10.1007/978-3-030-01722-4\_3) suggested the maximal perfect haplotype block as a very simple combinatorial pattern, forming the basis of a new method to perform rapid genome-wide selection scans. The algorithm they presented for identifying these blocks, however, had a worst-case running time quadratic in the genome length. It was posed as an open problem whether an optimal, linear-time algorithm exists. In this paper we give two algorithms that achieve this time bound, one conceptually very simple one using suffix trees and a second one using the positional Burrows--Wheeler Transform, that is very efficient also in practice.},
  langid = {english},
  file = {/Users/msgro/Zotero/storage/3M3YBTFM/Alanko et al. - 2020 - Finding all maximal perfect haplotype blocks in linear time.pdf}
}

@article{bonizzoniDataStructuresSMEMFinding2023,
  title = {Data {{Structures}} for {{SMEM-Finding}} in the {{PBWT}}},
  author = {Bonizzoni, Paola and Boucher, Christina and Cozzi, Davide and Gagie, Travis and K{\"o}ppl, Dominik and Rossi, Massimiliano},
  year = {2023},
  month = sep,
  journal = {International Symposium on String Processing and Information Retrieval : SPIRE ... : proceedings. SPIRE (Symposium)},
  volume = {14240},
  pages = {89--101},
  doi = {10.1007/978-3-031-43980-3_8},
  urldate = {2025-04-17},
  abstract = {The positional Burrows--Wheeler Transform (PBWT) was presented as a means to find set-maximal exact matches (SMEMs) in haplotype data via the computation of the divergence array. Although run-length encoding the PBWT has been previously considered, storing the divergence array along with the PBWT in a compressed manner has not been as rigorously studied. We define two queries that can be used in combination to compute SMEMs, allowing us to define smaller data structures that support one or both of these queries. We combine these data structures, enabling the PBWT and the divergence array to be stored in a manner that allows for finding SMEMs. We estimate and compare the memory usage of these data structures, leading to one data structure that is most memory efficient. Lastly, we implement this data structure and compare its performance to prior methods using various datasets taken from the 1000 Genomes Project data.},
  pmcid = {PMC11325217},
  pmid = {39149146},
  file = {/Users/msgro/Zotero/storage/AWWPG2KM/Bonizzoni et al. - 2023 - Data Structures for SMEM-Finding in the PBWT.pdf}
}

@incollection{bonizzoniMultiallelicMaximalPerfect2023,
  title = {Multiallelic {{Maximal Perfect Haplotype Blocks}} with {{Wildcards}} via {{PBWT}}},
  booktitle = {Bioinformatics and {{Biomedical Engineering}}},
  author = {Bonizzoni, Paola and Della Vedova, Gianluca and Pirola, Yuri and Rizzi, Raffaella and Sgr{\`o}, Mattia},
  editor = {Rojas, Ignacio and Valenzuela, Olga and Rojas Ruiz, Fernando and Herrera, Luis Javier and Ortu{\~n}o, Francisco},
  year = {2023},
  volume = {13919},
  pages = {62--76},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-34953-9_5},
  urldate = {2025-03-17},
  abstract = {Computing maximal perfect blocks of a given panel of haplotypes is a crucial task for efficiently solving problems such as polyploid haplotype reconstruction and finding identical-by-descent segments shared among individuals of a population. Unfortunately, the presence of missing data in the haplotype panel limits the usefulness of the notion of perfect blocks.},
  isbn = {978-3-031-34952-2 978-3-031-34953-9},
  langid = {english},
  file = {/Users/msgro/Zotero/storage/BV56MJ6L/Bonizzoni et al. - 2023 - Multiallelic Maximal Perfect Haplotype Blocks with Wildcards via PBWT.pdf}
}

@article{cozziPBWTLightweightRindexing2023,
  title = {{$\mu$}- {{PBWT}}: A Lightweight r-Indexing of the {{PBWT}} for Storing and Querying {{UK Biobank}} Data},
  shorttitle = {{$\mu$}- {{PBWT}}},
  author = {Cozzi, Davide and Rossi, Massimiliano and Rubinacci, Simone and Gagie, Travis and K{\"o}ppl, Dominik and Boucher, Christina and Bonizzoni, Paola},
  year = {2023},
  month = sep,
  journal = {Bioinformatics},
  volume = {39},
  number = {9},
  pages = {btad552},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btad552},
  urldate = {2025-04-17},
  abstract = {Motivation The Positional Burrows--Wheeler Transform (PBWT) is a data structure that indexes haplotype sequences in a manner that enables finding maximal haplotype matches in h sequences containing w variation sites in O(hw) time. This represents a significant improvement over classical quadratic-time approaches. However, the original PBWT data structure does not allow for queries over Biobank panels that consist of several millions of haplotypes, if an index of the haplotypes must be kept entirely in memory. Results In this article, we leverage the notion of r-index proposed for the BWT to present a memory-efficient method for constructing and storing the run-length encoded PBWT, and computing set maximal matches (SMEMs) queries in haplotype sequences. We implement our method, which we refer to as {$\mu$}-PBWT, and evaluate it on datasets of 1000 Genome Project and UK Biobank data. Our experiments demonstrate that the {$\mu$}-PBWT reduces the memory usage up to a factor of 20\% compared to the best current PBWT-based indexing. In particular, {$\mu$}-PBWT produces an index that stores high-coverage whole genome sequencing data of chromosome 20 in about a third of the space of its BCF file. {$\mu$}-PBWT is an adaptation of techniques for the run-length compressed BWT for the PBWT (RLPBWT) and it is based on keeping in memory only a succinct representation of the RLPBWT that still allows the efficient computation of set maximal matches (SMEMs) over the original panel. Availability and implementation Our implementation is open source and available at https://github.com/dlcgold/muPBWT. The binary is available at https://bioconda.github.io/recipes/mupbwt/README.html.},
  pmcid = {PMC10502237},
  pmid = {37688560},
  file = {/Users/msgro/Zotero/storage/9HHX3TMV/Cozzi et al. - 2023 - μ- PBWT a lightweight r-indexing of the PBWT for storing and querying UK Biobank data.pdf}
}

@article{cozziPBWTLightweightRindexing2023a,
  title = {{$\mu$}- {{PBWT}}: A Lightweight r-Indexing of the {{PBWT}} for Storing and Querying {{UK Biobank}} Data},
  shorttitle = {{$\mu$}- {{PBWT}}},
  author = {Cozzi, Davide and Rossi, Massimiliano and Rubinacci, Simone and Gagie, Travis and K{\"o}ppl, Dominik and Boucher, Christina and Bonizzoni, Paola},
  year = {2023},
  month = sep,
  journal = {Bioinformatics (Oxford, England)},
  volume = {39},
  number = {9},
  pages = {btad552},
  issn = {1367-4811},
  doi = {10.1093/bioinformatics/btad552},
  abstract = {MOTIVATION: The Positional Burrows-Wheeler Transform (PBWT) is a data structure that indexes haplotype sequences in a manner that enables finding maximal haplotype matches in h sequences containing w variation sites in O(hw) time. This represents a significant improvement over classical quadratic-time approaches. However, the original PBWT data structure does not allow for queries over Biobank panels that consist of several millions of haplotypes, if an index of the haplotypes must be kept entirely in memory. RESULTS: In this article, we leverage the notion of r-index proposed for the BWT to present a memory-efficient method for constructing and storing the run-length encoded PBWT, and computing set maximal matches (SMEMs) queries in haplotype sequences. We implement our method, which we refer to as {$\mu$}-PBWT, and evaluate it on datasets of 1000 Genome Project and UK Biobank data. Our experiments demonstrate that the {$\mu$}-PBWT reduces the memory usage up to a factor of 20\% compared to the best current PBWT-based indexing. In particular, {$\mu$}-PBWT produces an index that stores high-coverage whole genome sequencing data of chromosome 20 in about a third of the space of its BCF file. {$\mu$}-PBWT is an adaptation of techniques for the run-length compressed BWT for the PBWT (RLPBWT) and it is based on keeping in memory only a succinct representation of the RLPBWT that still allows the efficient computation of set maximal matches (SMEMs) over the original panel. AVAILABILITY AND IMPLEMENTATION: Our implementation is open source and available at https://github.com/dlcgold/muPBWT. The binary is available at https://bioconda.github.io/recipes/mupbwt/README.html.},
  langid = {english},
  pmcid = {PMC10502237},
  pmid = {37688560},
  keywords = {Biological Specimen Banks,Haplotypes,United Kingdom,Whole Genome Sequencing},
  file = {/Users/msgro/Zotero/storage/LVRFPHIF/Cozzi et al. - 2023 - μ- PBWT a lightweight r-indexing of the PBWT for storing and querying UK Biobank data.pdf}
}

@incollection{cunhaIdentifyingMaximalPerfect2018,
  title = {Identifying {{Maximal Perfect Haplotype Blocks}}},
  booktitle = {Advances in {{Bioinformatics}} and {{Computational Biology}}},
  author = {Cunha, Lu{\'i}s and Diekmann, Yoan and Kowada, Luis and Stoye, Jens},
  editor = {Alves, Ronnie},
  year = {2018},
  volume = {11228},
  pages = {26--37},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-01722-4_3},
  urldate = {2025-03-17},
  abstract = {The concept of maximal perfect haplotype blocks is introduced as a simple pattern allowing to identify genomic regions that show signatures of natural selection. The model is formally defined and a simple algorithm is presented to find all perfect haplotype blocks in a set of phased chromosome sequences. Application to three whole chromosomes from the 1000 genomes project phase 3 data set shows the potential of the concept as an effective approach for quick detection of selection in large sets of thousands of genomes.},
  isbn = {978-3-030-01721-7 978-3-030-01722-4},
  langid = {english},
  file = {/Users/msgro/Zotero/storage/JQMKYT4U/Cunha et al. - 2018 - Identifying Maximal Perfect Haplotype Blocks.pdf}
}

@article{durbinEfficientHaplotypeMatching2014,
  title = {Efficient Haplotype Matching and Storage Using the Positional {{Burrows}}--{{Wheeler}} Transform ({{PBWT}})},
  author = {Durbin, Richard},
  year = {2014},
  month = may,
  journal = {Bioinformatics},
  volume = {30},
  number = {9},
  pages = {1266--1272},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btu014},
  urldate = {2025-03-17},
  abstract = {Motivation: Over the last few years, methods based on suffix arrays using the Burrows--Wheeler Transform have been widely used for DNA sequence read matching and assembly. These provide very fast search algorithms, linear in the search pattern size, on a highly compressible representation of the dataset being searched. Meanwhile, algorithmic development for genotype data has concentrated on statistical methods for phasing and imputation, based on probabilistic matching to hidden Markov model representations of the reference data, which while powerful are much less computationally efficient. Here a theory of haplotype matching using suffix array ideas is developed, which should scale too much larger datasets than those currently handled by genotype algorithms.Results: Given M sequences with N bi-allelic variable sites, an O(NM) algorithm to derive a representation of the data based on positional prefix arrays is given, which is termed the positional Burrows--Wheeler transform (PBWT). On large datasets this compresses with run-length encoding by more than a factor of a hundred smaller than using gzip on the raw data. Using this representation a method is given to find all maximal haplotype matches within the set in O(NM) time rather than O(NM2) as expected from naive pairwise comparison, and also a fast algorithm, empirically independent of M given sufficient memory for indexes, to find maximal matches between a new sequence and the set. The discussion includes some proposals about how these approaches could be used for imputation and phasing.Availability: ~http://github.com/richarddurbin/pbwtContact: ~richard.durbin@sanger.ac.uk},
  file = {/Users/msgro/Zotero/storage/E9DA2K8Y/Durbin - 2014 - Efficient haplotype matching and storage using the positional Burrows–Wheeler transform (PBWT).pdf;/Users/msgro/Zotero/storage/NSF3BK22/236397.html}
}

@article{freymanFastRobustIdentitybyDescent2021,
  title = {Fast and {{Robust Identity-by-Descent Inference}} with the {{Templated Positional Burrows}}--{{Wheeler Transform}}},
  author = {Freyman, William A and McManus, Kimberly F and Shringarpure, Suyash S and Jewett, Ethan M and Bryc, Katarzyna and {The 23 and Me Research Team} and Auton, Adam},
  year = {2021},
  month = may,
  journal = {Molecular Biology and Evolution},
  volume = {38},
  number = {5},
  pages = {2131--2151},
  issn = {1537-1719},
  doi = {10.1093/molbev/msaa328},
  urldate = {2025-03-17},
  abstract = {Estimating the genomic location and length of identical-by-descent (IBD) segments among individuals is a crucial step in many genetic analyses. However, the exponential growth in the size of biobank and direct-to-consumer genetic data sets makes accurate IBD inference a significant computational challenge. Here we present the templated positional Burrows--Wheeler transform (TPBWT) to make fast IBD estimates robust to genotype and phasing errors. Using haplotype data simulated over pedigrees with realistic genotyping and phasing errors, we show that the TPBWT outperforms other state-of-the-art IBD inference algorithms in terms of speed and accuracy. For each phase-aware method, we explore the false positive and false negative rates of inferring IBD by segment length and characterize the types of error commonly found. Our results highlight the fragility of most phased IBD inference methods; the accuracy of IBD estimates can be highly sensitive to the quality of haplotype phasing. Additionally, we compare the performance of the TPBWT against a widely used phase-free IBD inference approach that is robust to phasing errors. We introduce both in-sample and out-of-sample TPBWT-based IBD inference algorithms and demonstrate their computational efficiency on massive-scale data sets with millions of samples. Furthermore, we describe the binary file format for TPBWT-compressed haplotypes that results in fast and efficient out-of-sample IBD computes against very large cohort panels. Finally, we demonstrate the utility of the TPBWT in a brief empirical analysis, exploring geographic patterns of haplotype sharing within Mexico. Hierarchical clustering of IBD shared across regions within Mexico reveals geographically structured haplotype sharing and a strong signal of isolation by distance. Our software implementation of the TPBWT is freely available for noncommercial use in the code repository (https://github.com/23andMe/phasedibd, last accessed January 11, 2021).},
  file = {/Users/msgro/Zotero/storage/L597S2CS/Freyman et al. - 2021 - Fast and Robust Identity-by-Descent Inference with the Templated Positional Burrows–Wheeler Transfor.pdf;/Users/msgro/Zotero/storage/6VN3PN5W/6045959.html}
}

@article{karkkainenLinearWorkSuffix2006,
  title = {Linear Work Suffix Array Construction},
  author = {K{\"a}rkk{\"a}inen, Juha and Sanders, Peter and Burkhardt, Stefan},
  year = {2006},
  month = nov,
  journal = {J. ACM},
  volume = {53},
  number = {6},
  pages = {918--936},
  issn = {0004-5411},
  doi = {10.1145/1217856.1217858},
  urldate = {2025-03-17},
  abstract = {Suffix trees and suffix arrays are widely used and largely interchangeable index structures on strings and sequences. Practitioners prefer suffix arrays due to their simplicity and space efficiency while theoreticians use suffix trees due to linear-time construction algorithms and more explicit structure. We narrow this gap between theory and practice with a simple linear-time construction algorithm for suffix arrays. The simplicity is demonstrated with a C++ implementation of 50 effective lines of code. The algorithm is called DC3, which stems from the central underlying concept of difference cover. This view leads to a generalized algorithm, DC, that allows a space-efficient implementation and, moreover, supports the choice of a space--time tradeoff. For any v {$\in$} [1,{\textsurd}n], it runs in O(vn) time using O(n/{\textsurd}v) space in addition to the input string and the suffix array. We also present variants of the algorithm for several parallel and hierarchical memory models of computation. The algorithms for BSP and EREW-PRAM models are asymptotically faster than all previous suffix tree or array construction algorithms.},
  file = {/Users/msgro/Zotero/storage/RKMBK9HL/Kärkkäinen et al. - 2006 - Linear work suffix array construction.pdf}
}

@inproceedings{kasaiLinearTimeLongestCommonPrefixComputation2001a,
  title = {Linear-{{Time Longest-Common-Prefix Computation}} in {{Suffix Arrays}} and {{Its Applications}}},
  booktitle = {Combinatorial {{Pattern Matching}}},
  author = {Kasai, Toru and Lee, Gunho and Arimura, Hiroki and Arikawa, Setsuo and Park, Kunsoo},
  editor = {Landau, Gad M. and Amir, Amihood},
  year = {2001},
  pages = {181--192},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-48194-X_17},
  abstract = {We present a linear-time algorithm to compute the longest common prefix information in suffix arrays. As two applications of our algorithm, we show that our algorithm is crucial to the effective use of block-sorting compression, and we present a linear-time algorithm to sim- ulate the bottom-up traversal of a suffix tree with a suffix array combined with the longest common prefix information.},
  isbn = {978-3-540-48194-2},
  langid = {english},
  keywords = {Compact Tree,Internal Node,Lower Common Ancestor,Suffix Array,Text Database},
  file = {/Users/msgro/Zotero/storage/XL3LHTDJ/Kasai et al. - 2001 - Linear-Time Longest-Common-Prefix Computation in Suffix Arrays and Its Applications.pdf}
}

@article{khanFastParallelCachefriendly2024,
  title = {Fast, Parallel, and Cache-Friendly Suffix Array Construction},
  author = {Khan, Jamshed and Rubel, Tobias and Molloy, Erin and Dhulipala, Laxman and Patro, Rob},
  year = {2024},
  month = apr,
  journal = {Algorithms for Molecular Biology},
  volume = {19},
  number = {1},
  pages = {16},
  issn = {1748-7188},
  doi = {10.1186/s13015-024-00263-5},
  urldate = {2025-03-17},
  abstract = {String indexes such as the suffix array (sa) and the closely related longest common prefix (lcp) array are fundamental objects in bioinformatics and have a wide variety of applications. Despite their importance in practice, few scalable parallel algorithms for constructing these are known, and the existing algorithms can be highly non-trivial to implement and parallelize.},
  langid = {english},
  keywords = {Data structures,Indexing,Longest common prefix,Parallel algorithms,Suffix array},
  file = {/Users/msgro/Zotero/storage/WBU4Z6HB/Khan et al. - 2024 - Fast, parallel, and cache-friendly suffix array construction.pdf}
}

@inproceedings{naseriEfficientHaplotypeBlock2021,
  title = {Efficient {{Haplotype Block Matching}} in {{Bi-Directional PBWT}}},
  booktitle = {21st {{International Workshop}} on {{Algorithms}} in {{Bioinformatics}} ({{WABI}} 2021)},
  author = {Naseri, Ardalan and Yue, William and Zhang, Shaojie and Zhi, Degui},
  editor = {Carbone, Alessandra and {El-Kebir}, Mohammed},
  year = {2021},
  series = {Leibniz {{International Proceedings}} in {{Informatics}} ({{LIPIcs}})},
  volume = {201},
  pages = {19:1--19:13},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address = {Dagstuhl, Germany},
  issn = {1868-8969},
  doi = {10.4230/LIPIcs.WABI.2021.19},
  urldate = {2025-03-17},
  isbn = {978-3-95977-200-6},
  keywords = {Bi-directional,Haplotype Matching,PBWT},
  file = {/Users/msgro/Zotero/storage/WAXFG6RP/Naseri et al. - 2021 - Efficient Haplotype Block Matching in Bi-Directional PBWT.pdf;/Users/msgro/Zotero/storage/GMD6SFNB/LIPIcs.WABI.2021.html}
}

@article{naseriEfficientHaplotypeMatching2019,
  title = {Efficient Haplotype Matching between a Query and a Panel for Genealogical Search},
  author = {Naseri, Ardalan and Holzhauser, Erwin and Zhi, Degui and Zhang, Shaojie},
  year = {2019},
  month = jul,
  journal = {Bioinformatics},
  volume = {35},
  number = {14},
  pages = {i233-i241},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btz347},
  urldate = {2025-04-18},
  abstract = {With the wide availability of whole-genome genotype data, there is an increasing need for conducting genetic genealogical searches efficiently. Computationally, this task amounts to identifying shared DNA segments between a query individual and a very large panel containing millions of haplotypes. The celebrated Positional Burrows-Wheeler Transform (PBWT) data structure is a pre-computed index of the panel that enables constant time matching at each position between one haplotype and an arbitrarily large panel. However, the existing algorithm (Durbin's Algorithm 5) can only identify set-maximal matches, the longest matches ending at any location in a panel, while in real genealogical search scenarios, multiple `good enough' matches are desired.In this work, we developed two algorithmic extensions of Durbin's Algorithm 5, that can find all L-long matches, matches longer than or equal to a given length L, between a query and a panel. In the first algorithm, PBWT-Query, we introduce `virtual insertion' of the query into the PBWT matrix of the panel, and then scanning up and down for the PBWT match blocks with length greater than L. In our second algorithm, L-PBWT-Query, we further speed up PBWT-Query by introducing additional data structures that allow us to avoid iterating through blocks of incomplete matches. The efficiency of PBWT-Query and L-PBWT-Query is demonstrated using the simulated data and the UK Biobank data. Our results show that our proposed algorithms can detect related individuals for a given query efficiently in very large cohorts which enables a fast on-line query search.genome.ucf.edu/pbwt-querySupplementary data are available at Bioinformatics online.},
  file = {/Users/msgro/Zotero/storage/ZC7YRJ4T/Naseri et al. - 2019 - Efficient haplotype matching between a query and a panel for genealogical search.pdf;/Users/msgro/Zotero/storage/MLMGH794/5529240.html}
}

@article{sanaullahDPBWTDynamicPositional2021,
  title = {D-{{PBWT}}: Dynamic Positional {{Burrows}}--{{Wheeler}} Transform},
  shorttitle = {D-{{PBWT}}},
  author = {Sanaullah, Ahsan and Zhi, Degui and Zhang, Shaojie},
  year = {2021},
  month = aug,
  journal = {Bioinformatics},
  volume = {37},
  number = {16},
  pages = {2390--2397},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btab117},
  urldate = {2025-03-17},
  abstract = {Durbin's positional Burrows--Wheeler transform (PBWT) is a scalable data structure for haplotype matching. It has been successfully applied to identical by descent (IBD) segment identification and genotype imputation. Once the PBWT of a haplotype panel is constructed, it supports efficient retrieval of all shared long segments among all individuals (long matches) and efficient query between an external haplotype and the panel. However, the standard PBWT is an array-based static data structure and does not support dynamic updates of the panel.Here, we generalize the static PBWT to a dynamic data structure, d-PBWT, where the reverse prefix sorting at each position is stored with linked lists. We also developed efficient algorithms for insertion and deletion of individual haplotypes. In addition, we verified that d-PBWT can support all algorithms of PBWT. In doing so, we systematically investigated variations of set maximal match and long match query algorithms: while they all have average case time complexity independent of database size, they have different worst case complexities and dependencies on additional data structures.The benchmarking code is available at genome.ucf.edu/d-PBWT.Supplementary data are available at Bioinformatics online.},
  file = {/Users/msgro/Zotero/storage/NGVAPB9H/Sanaullah et al. - 2021 - d-PBWT dynamic positional Burrows–Wheeler transform.pdf;/Users/msgro/Zotero/storage/ZW4BAVD5/6149123.html}
}

@misc{sanaullahHaplotypeMatchingGBWT2025,
  title = {Haplotype {{Matching}} with {{GBWT}} for {{Pangenome Graphs}}},
  author = {Sanaullah, Ahsan and Villalobos, Seba and Zhi, Degui and Zhang, Shaojie},
  year = {2025},
  month = feb,
  primaryclass = {New Results},
  pages = {2025.02.03.634410},
  publisher = {bioRxiv},
  doi = {10.1101/2025.02.03.634410},
  urldate = {2025-03-17},
  abstract = {Traditionally, variations from a linear reference genome were used to represent large sets of haplotypes compactly. In the linear reference genome based paradigm, the positional Burrows-Wheeler transform (PBWT) has traditionally been used to perform efficient haplotype matching. Pangenome graphs have recently been proposed as an alternative to linear reference genomes for representing the full spectrum of variations in the human genome. However, haplotype matches in pangenome graph based haplotype sets are not trivially generalizable from haplotype matches in the linear reference genome based haplotype sets. Work has been done to represent large sets of haplotypes as paths through a pangenome graph. The graph Burrows-Wheeler transform (GBWT) is one such work. The GBWT essentially stores the haplotype paths in a run length compressed BWT with compressed local alphabets. Although efficient in practice count and locate queries on the GBWT were provided by the original authors, the efficient haplotype matching capabilities of the PBWT have never been shown on the GBWT. In this paper, we formally define the notion of haplotype matches in pangenome graph-based haplotype sets by generalizing from haplotype matches in linear reference genome-based haplotype sets. We also describe the relationship between set maximal matches, long matches, locally maximal matches, and text maximal matches on the GBWT, PBWT, and the BWT. We provide algorithms for outputting some of these matches by applying the data structures of the r-index (introduced by Gagie et al.) to the GBWT. We show that these structures enable set maximal match and long match queries on the GBWT in almost linear time and in space close to linear in the number of runs in the GBWT. We also provide multiple versions of the query algorithms for different combinations of the available data structures. The long match query algorithms presented here even run on the BWT in the same time complexity as the GBWT due to their similarity.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {{\copyright} 2025, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/msgro/Zotero/storage/KPVGYXCM/Sanaullah et al. - 2025 - Haplotype Matching with GBWT for Pangenome Graphs.pdf}
}

@misc{sanaullahHaplotypeMatchingGBWT2025a,
  title = {Haplotype {{Matching}} with {{GBWT}} for {{Pangenome Graphs}}},
  author = {Sanaullah, Ahsan and Villalobos, Seba and Zhi, Degui and Zhang, Shaojie},
  year = {2025},
  month = feb,
  publisher = {Bioinformatics},
  doi = {10.1101/2025.02.03.634410},
  urldate = {2025-03-17},
  abstract = {Traditionally, variations from a linear reference genome were used to represent large sets of haplotypes compactly. In the linear reference genome based paradigm, the positional Burrows-Wheeler transform (PBWT) has traditionally been used to perform efficient haplotype matching. Pangenome graphs have recently been proposed as an alternative to linear reference genomes for representing the full spectrum of variations in the human genome. However, haplotype matches in pangenome graph based haplotype sets are not trivially generalizable from haplotype matches in the linear reference genome based haplotype sets. Work has been done to represent large sets of haplotypes as paths through a pangenome graph. The graph Burrows-Wheeler transform (GBWT) is one such work. The GBWT essentially stores the haplotype paths in a run length compressed BWT with compressed local alphabets. Although efficient in practice count and locate queries on the GBWT were provided by the original authors, the efficient haplotype matching capabilities of the PBWT have never been shown on the GBWT. In this paper, we formally define the notion of haplotype matches in pangenome graph-based haplotype sets by generalizing from haplotype matches in linear reference genome-based haplotype sets. We also describe the relationship between set maximal matches, long matches, locally maximal matches, and text maximal matches on the GBWT, PBWT, and the BWT. We provide algorithms for outputting some of these matches by applying the data structures of the r-index (introduced by Gagie et al.) to the GBWT. We show that these structures enable set maximal match and long match queries on the GBWT in almost linear time and in space close to linear in the number of runs in the GBWT. We also provide multiple versions of the query algorithms for different combinations of the available data structures. The long match query algorithms presented here even run on the BWT in the same time complexity as the GBWT due to their similarity.},
  archiveprefix = {Bioinformatics},
  copyright = {http://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/msgro/Zotero/storage/PASEUXQ7/Sanaullah et al. - 2025 - Haplotype Matching with GBWT for Pangenome Graphs.pdf}
}

@inproceedings{sanaullahHaplotypeThreadingUsing2022,
  title = {Haplotype {{Threading Using}} the {{Positional Burrows-Wheeler Transform}}},
  booktitle = {22nd {{International Workshop}} on {{Algorithms}} in {{Bioinformatics}} ({{WABI}} 2022)},
  author = {Sanaullah, Ahsan and Zhi, Degui and Zhang, Shaoije},
  editor = {Boucher, Christina and Rahmann, Sven},
  year = {2022},
  series = {Leibniz {{International Proceedings}} in {{Informatics}} ({{LIPIcs}})},
  volume = {242},
  pages = {4:1--4:14},
  publisher = {Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik},
  address = {Dagstuhl, Germany},
  issn = {1868-8969},
  doi = {10.4230/LIPIcs.WABI.2022.4},
  urldate = {2025-03-17},
  isbn = {978-3-95977-243-3},
  keywords = {Haplotype Matching,Haplotype Threading,PBWT,Substring Cover},
  file = {/Users/msgro/Zotero/storage/X35CVF27/Sanaullah et al. - 2022 - Haplotype Threading Using the Positional Burrows-Wheeler Transform.pdf;/Users/msgro/Zotero/storage/S6NNF359/LIPIcs.WABI.2022.html}
}

@article{shakyaDynamicMPBWTDynamic2025,
  title = {Dynamic {$\mu$}-{{PBWT}}: {{Dynamic Run-length Compressed PBWT}} for {{Biobank Scale Data}}},
  shorttitle = {Dynamic {$\mu$}-{{PBWT}}},
  author = {Shakya, Pramesh and Sanaullah, Ahsan and Zhi, Degui and Zhang, Shaojie},
  year = {2025},
  month = feb,
  journal = {bioRxiv},
  pages = {2025.02.04.636479},
  issn = {2692-8205},
  doi = {10.1101/2025.02.04.636479},
  urldate = {2025-04-18},
  abstract = {Durbin's positional Burrows-Wheeler transform (PBWT) supports efficient haplotype matching and queries given a panel of haplotypes. It has been widely used for statistical phasing, imputation and identity-by-descent (IBD) detection. However, the original PBWT panel doesn't support dynamic updates when haplotypes need to be added or deleted from the panel. Dynamic-PBWT (d-PBWT) solved this problem but it is not memory efficient. While the memory constraint problem of the PBWT has been tackled by Syllable-PBWT and {$\mu$}-PBWT, these are static data structures that do not allow updates. Additionally, Syllable-PBWT only supports long-match query and {$\mu$}-PBWT only supports set-maximal match query, limiting their functionality in the compressed form. In this paper, we present Dynamic {$\mu$}-PBWT (which can also be seen as compressed d-PBWT) that is memory efficient and supports dynamic updates. We run-length compress PBWT to achieve better compression rate and store the runs in the self-balancing trees to enable dynamic updates. We show that the number of updates per insertion or deletion in the tree at each site is constant regardless of the number of haplotypes in the panel and the updates can be made without decompressing the index. In addition, we use orders of magnitude less memory than d-PBWT. We also provide a long match query algorithm that can easily be extended back to the original {$\mu$}-PBWT. Overall, the flexibility and space-efficiency of Dynamic {$\mu$}-PBWT makes it a potential index data structure for biobank scale genetic data analyses. The source code for Dynamic {$\mu$}-PBWT is available at https://github.com/ucfcbb/Dynamic-mu-PBWT.},
  pmcid = {PMC11838588},
  pmid = {39975111},
  file = {/Users/msgro/Zotero/storage/FMJHPH2G/Shakya et al. - 2025 - Dynamic μ-PBWT Dynamic Run-length Compressed PBWT for Biobank Scale Data.pdf}
}

@inproceedings{shakyaMcPBWTSpaceEfficientMulticolumn2022,
  title = {{{mcPBWT}}: {{Space-Efficient Multi-column PBWT Scanning Algorithm}} for~{{Composite Haplotype Matching}}},
  shorttitle = {{{mcPBWT}}},
  booktitle = {Computational {{Advances}} in {{Bio}} and {{Medical Sciences}}},
  author = {Shakya, Pramesh and Naseri, Ardalan and Zhi, Degui and Zhang, Shaojie},
  editor = {Bansal, Mukul S. and M{\u a}ndoiu, Ion and Moussa, Marmar and Patterson, Murray and Rajasekaran, Sanguthevar and Skums, Pavel and Zelikovsky, Alexander},
  year = {2022},
  pages = {115--130},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-17531-2_10},
  abstract = {Positional Burrows-Wheeler Transform (PBWT) is a data structure that supports efficient algorithms for finding matching segments in a panel of haplotypes. It is of interest to study the composite patterns of multiple matching segments or blocks arranged contiguously along a same haplotype as they can indicate recombination crossover events, gene-conversion tracts, or, sometimes, errors of phasing algorithms. However, current PBWT algorithms do not support search of such composite patterns efficiently. Here, we present our algorithm, mcPBWT (multi-column PBWT), that uses multiple synchronized runs of PBWT at different variant sites providing a ``look-ahead" information of matches at those variant sites. Such ``look-ahead'' information allows us to analyze multiple contiguous matching pairs in a single pass. We present two specific cases of mcPBWT, namely double-PBWT and triple-PBWT which utilize two and three columns of PBWT respectively. double-PBWT finds two matching pairs' combinations representative of crossover event or phasing error while triple-PBWT finds three matching pairs' combinations representative of gene-conversion tract.},
  isbn = {978-3-031-17531-2},
  langid = {english},
  keywords = {Gene conversion,Haplotype match,PBWT,Recombination},
  file = {/Users/msgro/Zotero/storage/9TGBNJEI/Shakya et al. - 2022 - mcPBWT Space-Efficient Multi-column PBWT Scanning Algorithm for Composite Haplotype Matching.pdf}
}

@incollection{shakyaMcPBWTSpaceEfficientMulticolumn2022a,
  title = {{{mcPBWT}}: {{Space-Efficient Multi-column PBWT Scanning Algorithm}} for {{Composite Haplotype Matching}}},
  shorttitle = {{{mcPBWT}}},
  booktitle = {Computational {{Advances}} in {{Bio}} and {{Medical Sciences}}},
  author = {Shakya, Pramesh and Naseri, Ardalan and Zhi, Degui and Zhang, Shaojie},
  editor = {Bansal, Mukul S. and M{\u a}ndoiu, Ion and Moussa, Marmar and Patterson, Murray and Rajasekaran, Sanguthevar and Skums, Pavel and Zelikovsky, Alexander},
  year = {2022},
  volume = {13254},
  pages = {115--130},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-17531-2_10},
  urldate = {2025-03-17},
  abstract = {Positional Burrows-Wheeler Transform (PBWT) is a data structure that supports efficient algorithms for finding matching segments in a panel of haplotypes. It is of interest to study the composite patterns of multiple matching segments or blocks arranged contiguously along a same haplotype as they can indicate recombination crossover events, gene-conversion tracts, or, sometimes, errors of phasing algorithms. However, current PBWT algorithms do not support search of such composite patterns efficiently. Here, we present our algorithm, mcPBWT (multi-column PBWT), that uses multiple synchronized runs of PBWT at different variant sites providing a ``look-ahead'' information of matches at those variant sites. Such ``look-ahead'' information allows us to analyze multiple contiguous matching pairs in a single pass. We present two specific cases of mcPBWT, namely double-PBWT and triple-PBWT which utilize two and three columns of PBWT respectively. double-PBWT finds two matching pairs' combinations representative of crossover event or phasing error while triple-PBWT finds three matching pairs' combinations representative of gene-conversion tract.},
  isbn = {978-3-031-17530-5 978-3-031-17531-2},
  langid = {english},
  file = {/Users/msgro/Zotero/storage/7E5WQCAQ/Shakya et al. - 2022 - mcPBWT Space-Efficient Multi-column PBWT Scanning Algorithm for Composite Haplotype Matching.pdf}
}

@article{sirenHaplotypeawareGraphIndexes2020,
  title = {Haplotype-Aware Graph Indexes},
  author = {Sir{\'e}n, Jouni and Garrison, Erik and Novak, Adam M and Paten, Benedict and Durbin, Richard},
  year = {2020},
  month = jan,
  journal = {Bioinformatics},
  volume = {36},
  number = {2},
  pages = {400--407},
  issn = {1367-4803},
  doi = {10.1093/bioinformatics/btz575},
  urldate = {2025-03-17},
  abstract = {The variation graph toolkit (VG) represents genetic variation as a graph. Although each path in the graph is a potential haplotype, most paths are non-biological, unlikely recombinations of true haplotypes.We augment the VG model with haplotype information to identify which paths are more likely to exist in nature. For this purpose, we develop a scalable implementation of the graph extension of the positional Burrows--Wheeler transform. We demonstrate the scalability of the new implementation by building a whole-genome index of the 5008 haplotypes of the 1000 Genomes Project, and an index of all 108~070 Trans-Omics for Precision Medicine Freeze 5 chromosome 17 haplotypes. We also develop an algorithm for simplifying variation graphs for k-mer indexing without losing any k-mers in the haplotypes.Our software is available at https://github.com/vgteam/vg, https://github.com/jltsiren/gbwt and https://github.com/jltsiren/gcsa2.Supplementary data are available at Bioinformatics online.},
  file = {/Users/msgro/Zotero/storage/EDTQXRQX/Sirén et al. - 2020 - Haplotype-aware graph indexes.pdf;/Users/msgro/Zotero/storage/WS7SFMUZ/5538990.html}
}

@misc{tangHaplotypebasedParallelPBWT2025,
  title = {Haplotype-Based {{Parallel PBWT}} for {{Biobank Scale Data}}},
  author = {Tang, Kecong and Sanaullah, Ahsan and Zhi, Degui and Zhang, Shaojie},
  year = {2025},
  month = feb,
  primaryclass = {New Results},
  pages = {2025.02.04.636317},
  publisher = {bioRxiv},
  doi = {10.1101/2025.02.04.636317},
  urldate = {2025-04-18},
  abstract = {Durbin's positional Burrows-Wheeler transform (PBWT) enables algorithms with the optimal time complexity of O(MN) for reporting all vs all haplotype matches in a population panel with M haplotypes and N variant sites. However, even this efficiency may still be too slow when the number of haplotypes reaches millions. To further reduce the run time, in this paper, a parallel version of the PBWT algorithms is introduced for all versus all haplotype matching, which is called HP-PBWT (haplotype-based parallel PBWT). HP-PBWT parallelly executes the PBWT by splitting a haplotype panel into blocks of haplotypes. HP-PBWT algorithms achieve parallelization for PBWT construction, reporting all versus all L-long matches, and reporting all versus all set-maximal matches while maintaining memory efficiency. HP-PBWT has an {$<$}img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2025/02/08/2025.02.04.636317/embed/inline-graphic-1.gif"/{$>$} time complexity in PBWT construction, and an {$<$}img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2025/02/08/2025.02.04.636317/embed/inline-graphic-2.gif"/{$>$} time complexity for reporting all versus all L-long matches and reporting all versus all set-maximal matches, where T is the number of threads and c* is the maximum number of matches (of length L or maximum divergence value for L-long matches and set-maximal matches, re-spectively) per haplotype per site. HP-PBWT achieves 4-fold speed-up in UK Biobank genotyping array data with 30 threads in the IO-included benchmarks. When applying HP-PBWT to a dataset of 8 million randomized haplotypes (random binary strings of equal length) in the IO-excluded benchmarks, it can achieve a 22-fold speed-up with 60 cores on the Amazon EC2 server. With further hardware optimization, HP-PBWT is expected to handle billions of haplotypes efficiently.},
  archiveprefix = {bioRxiv},
  chapter = {New Results},
  copyright = {{\copyright} 2025, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/msgro/Zotero/storage/ZV2QQWDM/Tang et al. - 2025 - Haplotype-based Parallel PBWT for Biobank Scale Data.pdf}
}

@article{wangSyllablePBWTSpaceefficientHaplotype2023,
  title = {Syllable-{{PBWT}} for Space-Efficient Haplotype Long-Match Query},
  author = {Wang, Victor and Naseri, Ardalan and Zhang, Shaojie and Zhi, Degui},
  year = {2023},
  month = jan,
  journal = {Bioinformatics},
  volume = {39},
  number = {1},
  pages = {btac734},
  issn = {1367-4811},
  doi = {10.1093/bioinformatics/btac734},
  urldate = {2025-03-17},
  abstract = {The positional Burrows--Wheeler transform (PBWT) has led to tremendous strides in haplotype matching on biobank-scale data. For genetic genealogical search, PBWT-based methods have optimized the asymptotic runtime of finding long matches between a query haplotype and a predefined panel of haplotypes. However, to enable fast query searches, the full-sized panel and PBWT data structures must be kept in memory, preventing existing algorithms from scaling up to modern biobank panels consisting of millions of haplotypes. In this work, we propose a space-efficient variation of PBWT named Syllable-PBWT, which divides every haplotype into syllables, builds the PBWT positional prefix arrays on the compressed syllabic panel, and leverages the polynomial rolling hash function for positional substring comparison. With the Syllable-PBWT data structures, we then present a long match query algorithm named Syllable-Query.Compared to the most time- and space-efficient previously published solution to the long match query problem, Syllable-Query reduced the memory use by a factor of over 100 on both the UK Biobank genotype data and the 1000 Genomes Project sequence data. Surprisingly, the smaller size of our syllabic data structures allows for more efficient iteration and CPU cache usage, granting Syllable-Query even faster runtime than existing solutions.https://github.com/ZhiGroup/Syllable-PBWTSupplementary data are available at Bioinformatics online.},
  file = {/Users/msgro/Zotero/storage/PII799H4/Wang et al. - 2023 - Syllable-PBWT for space-efficient haplotype long-match query.pdf;/Users/msgro/Zotero/storage/YHATS8QI/Wang et al. - SYLLABLE-PBWT FOR SPACE-EFFICIENT HAPLOTYPE LONG-MATCH QUERY.pdf;/Users/msgro/Zotero/storage/VG9WWDWD/6849513.html}
}

@article{Wertenbroek_2022,
  title = {{{XSI}} - {{A}} Genotype Compression Tool for Compressive Genomics in Large Biobanks},
  author = {Wertenbroek, Rick and Wertenbroek, Rick and Rubinacci, Simone and Rubinacci, Simone and X{\'e}narios, Ioannis and Xenarios, Ioannis and Thoma, Yann and Thoma, Yann and Delaneau, Olivier and Delaneau, Olivier},
  year = {2022},
  journal = {Bioinformatics (Oxford, England)},
  doi = {10.1093/bioinformatics/btac413},
  abstract = {Abstract Motivation Generation of genotype data has been growing exponentially over the last decade. With the large size of recent datasets comes a storage and computational burden with ever increasing costs. To reduce this burden we propose XSI, a file format with reduced storage footprint that also allows computation on the compressed data and we show how this can improve future analyses. Results We show that XSI allows for a file size reduction of 4-20x compared to compressed BCF and demonstrate its potential for ``compressive genomics'' on the UK Biobank whole genome sequencing genotypes with 8x faster loading times, 5x faster run of homozygozity computation, 30x faster dot products computation, and 280x faster allele counts. Availability The xSqueezeIt file format (XSI) specifications, API, and command line tool are released under open-source (MIT) license and are available at https://github.com/rwk-unil/xSqueezeIt Supplementary information Supplementary materials are available at Bioinformatics online.},
  mag_id = {4283447811},
  pmcid = {9344850},
  pmid = {35748697},
  file = {/Users/msgro/Zotero/storage/TK5TGASH/Wertenbroek et al. - 2022 - XSI - A genotype compression tool for compressive genomics in large biobanks.pdf}
}

@article{wertenbroekExploitingParallelizationPositional2023,
  title = {Exploiting Parallelization in Positional {{Burrows}}--{{Wheeler}} Transform ({{PBWT}}) Algorithms for Efficient Haplotype Matching and Compression},
  author = {Wertenbroek, Rick and Xenarios, Ioannis and Thoma, Yann and Delaneau, Olivier},
  year = {2023},
  month = jan,
  journal = {Bioinformatics Advances},
  volume = {3},
  number = {1},
  pages = {vbad021},
  issn = {2635-0041},
  doi = {10.1093/bioadv/vbad021},
  urldate = {2025-04-18},
  abstract = {The positional Burrows--Wheeler transform (PBWT) data structure allows for efficient haplotype data matching and compression. Its performance makes it a powerful tool for bioinformatics. However, existing algorithms do not exploit parallelism due to inner dependencies. We introduce a new method to break the dependencies and show how to fully exploit modern multi-core processors.Source code and applications are available at https://github.com/rwk-unil/parallel\_pbwt.Supplementary data are available at Bioinformatics Advances online.},
  file = {/Users/msgro/Zotero/storage/V4U5KBNU/Wertenbroek et al. - 2023 - Exploiting parallelization in positional Burrows–Wheeler transform (PBWT) algorithms for efficient h.pdf;/Users/msgro/Zotero/storage/54ZU6BU6/7067758.html}
}

@inproceedings{williamsExtendingMaximalPerfect2020,
  title = {Extending {{Maximal Perfect Haplotype Blocks}} to the {{Realm}} of {{Pangenomics}}},
  booktitle = {Algorithms for {{Computational Biology}}},
  author = {Williams, Lucia and Mumey, Brendan},
  editor = {{Mart{\'i}n-Vide}, Carlos and {Vega-Rodr{\'i}guez}, Miguel A. and Wheeler, Travis},
  year = {2020},
  pages = {41--48},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-42266-0_4},
  abstract = {Recent work provides the first method to measure the relative fitness of genomic variants within a population that scales to large numbers of genomes. A key component of the computation involves finding conserved haplotype blocks, which can be done in linear time. Here, we extend the notion of conserved haplotype blocks to pangenomes, which can store more complex variation than a single reference genome. We define a maximal perfect pangenome haplotype block and give a linear-time, suffix tree based approach to find all such blocks from a set of pangenome haplotypes. We demonstrate the method by applying it to a pangenome built from yeast strains.},
  isbn = {978-3-030-42266-0},
  langid = {english},
  keywords = {Haplotype block,Pangenomics,Population genomics},
  file = {/Users/msgro/Zotero/storage/IPR7AHC2/Williams e Mumey - 2020 - Extending Maximal Perfect Haplotype Blocks to the Realm of Pangenomics.pdf}
}

@article{williamsMaximalPerfectHaplotype2020,
  title = {Maximal {{Perfect Haplotype Blocks}} with {{Wildcards}}},
  author = {Williams, Lucia and Mumey, Brendan},
  year = {2020},
  month = may,
  issn = {2589-0042},
  urldate = {2025-03-17},
  abstract = {Recent work provides the first method to measure the relative fitness of genomic variants within a population that scales to large numbers of genomes. A key component of the computation involves finding maximal perfect haplotype blocks from a set of genomic samples for which SNPs (single-nucleotide polymorphisms) have been called. Often, owing to low read coverage and imperfect assemblies, some of the SNP calls can be missing from some of the samples. In this work, we consider the problem of finding maximal perfect haplotype blocks where some missing values may be present. Missing values are treated as wildcards, and the definition of maximal perfect haplotype blocks is extended in a natural way. We provide an output-linear time algorithm to identify all such blocks and demonstrate the algorithm on a large population SNP dataset. Our software is publicly available.},
  langid = {american},
  file = {/Users/msgro/Zotero/storage/HK2BUV2N/Williams e Mumey - 2020 - Maximal Perfect Haplotype Blocks with Wildcards.pdf}
}

@article{yuePsmootherEfficientPBWT2022,
  title = {P-Smoother: Efficient {{PBWT}} Smoothing of Large Haplotype Panels},
  shorttitle = {P-Smoother},
  author = {Yue, William and Naseri, Ardalan and Wang, Victor and Shakya, Pramesh and Zhang, Shaojie and Zhi, Degui},
  year = {2022},
  month = jan,
  journal = {Bioinformatics Advances},
  volume = {2},
  number = {1},
  pages = {vbac045},
  issn = {2635-0041},
  doi = {10.1093/bioadv/vbac045},
  urldate = {2025-03-17},
  abstract = {As large haplotype panels become increasingly available, efficient string matching algorithms such as positional Burrows-Wheeler transformation (PBWT) are promising for identifying shared haplotypes. However, recent mutations and genotyping errors create occasional mismatches, presenting challenges for exact haplotype matching. Previous solutions are based on probabilistic models or seed-and-extension algorithms that passively tolerate mismatches.Here, we propose a PBWT-based smoothing algorithm, P-smoother, to actively `correct' these mismatches and thus `smooth' the panel. P-smoother runs a bidirectional PBWT-based panel scanning that flips mismatching alleles based on the overall haplotype matching context, which we call the IBD (identical-by-descent) prior. In a simulated panel with 4000 haplotypes and a 0.2\% error rate, we show it can reliably correct 85\% of errors. As a result, PBWT algorithms running over the smoothed panel can identify more pairwise IBD segments than that over the unsmoothed panel. Most strikingly, a PBWT-cluster algorithm running over the smoothed panel, which we call PS-cluster, achieves state-of-the-art performance for identifying multiway IBD segments, a challenging problem in the computational community for years. We also showed that PS-cluster is adequately efficient for UK Biobank data. Therefore, P-smoother opens up new possibilities for efficient error-tolerating algorithms for biobank-scale haplotype panels.Source code is available at github.com/ZhiGroup/P-smoother.},
  file = {/Users/msgro/Zotero/storage/JM2BPQKF/Yue et al. - 2022 - P-smoother efficient PBWT smoothing of large haplotype panels.pdf;/Users/msgro/Zotero/storage/V2NGT3FS/6611715.html}
}
